{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFikF3svh3o"
      },
      "source": [
        "## NER命名实体识别\n",
        "\n",
        "### hugging face 的中文数据集\n",
        "- qgyd2021/chinese_ner_sft\n",
        "  - 有很多子集，数据格式如下\n",
        "  - 纯美韩国女主播性感热舞变形金刚\n",
        "  - { \"start_idx\": [ 2, 11 ], \"end_idx\": [ 4, 15 ], \"entity_text\": [ \"韩国\", \"变形金刚\" ], \"entity_label\": [ \"MISC\", \"TELEVISION\" ], \"entity_names\": [ [ \"其它实体\" ], [ \"电视\", \"电视节目\", \"影视作品\", \"影视节目\" ] ] }\n",
        "- peoples_daily_ner\n",
        "  - 这个是我理解的那种数据格式\n",
        "  - [ \"沙\", \"特\", \"队\", \"教\", \"练\", \"佩\", \"雷\", \"拉\", \"：\", \"两\", \"支\", \"队\", \"都\", \"想\", \"胜\", \"，\", \"因\", \"此\", \"都\", \"作\", \"出\", \"了\", \"最\", \"大\", \"的\", \"努\", \"力\", \"。\" ]\n",
        "  - [ 3, 4, 4, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "\n",
        "- 参考资料\n",
        "  - http://m.tnblog.net/hb/article/details/8266\n",
        "  - https://www.cnblogs.com/shengshengwang/p/17674861.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "OuYg_7pYvfyu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "3NYicuQEgvcM"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "I8sKulcw0Otn"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"peoples_daily_ner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pX2sP7_0Xhr",
        "outputId": "01f7bf2e-efd3-417c-f10a-1c7451067034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 20865\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 2319\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 4637\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxXa00Sx1aUN",
        "outputId": "135799fc-a53c-41e1-82dc-3f461ff07ccf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'ner_tags'],\n",
              "    num_rows: 20865\n",
              "})"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YiekL-kf3EQO"
      },
      "outputs": [],
      "source": [
        "# 初始化BERT tokenizer和模型\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3KP4_OEfyqr"
      },
      "source": [
        "##### 测试tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiTd8RoPfyMG",
        "outputId": "adf2bdc4-baac-414f-e029-900bbd55f4e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 海 钓 比 赛 地 点 在 厦 门 与 金 门 之 间 的 海 域 。 [SEP]\n",
            "[CLS] 这 座 依 山 傍 水 的 博 物 馆 由 国 内 一 流 的 设 计 [SEP]\n",
            "input_ids tensor([[ 101, 3862, 7157, 3683, 6612, 1765, 4157, 1762, 1336, 7305,  680, 7032,\n",
            "         7305,  722, 7313, 4638, 3862, 1818,  511,  102],\n",
            "        [ 101, 6821, 2429,  898, 2255,  988, 3717, 4638, 1300, 4289, 7667, 4507,\n",
            "         1744, 1079,  671, 3837, 4638, 6392, 6369,  102]])\n",
            "token_type_ids tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "# 编码测试\n",
        "out = tokenizer.batch_encode_plus(\n",
        "    [[\n",
        "        '海', '钓', '比', '赛', '地', '点', '在', '厦', '门', '与', '金', '门', '之', '间',\n",
        "        '的', '海', '域', '。'\n",
        "    ],\n",
        "     [\n",
        "         '这', '座', '依', '山', '傍', '水', '的', '博', '物', '馆', '由', '国', '内', '一',\n",
        "         '流', '的', '设', '计', '师', '主', '持', '设', '计', '。'\n",
        "     ]],\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='pt',\n",
        "    max_length=20,\n",
        "    is_split_into_words=True)\n",
        "#还原编码为句子\n",
        "print(tokenizer.decode(out['input_ids'][0]))\n",
        "print(tokenizer.decode(out['input_ids'][1]))\n",
        "for k, v in out.items():\n",
        "    print(k, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaZX5zq38DgQ",
        "outputId": "e6749dc9-88f6-4e64-93f3-9074d54c692b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"].features[\"ner_tags\"].feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de5cfvO-Ab2e",
        "outputId": "3e9a3c80-868d-4b0b-9d42-c9ae20ac0c6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset[\"train\"].features[\"ner_tags\"].feature.names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l6IkFdWw1ZzC"
      },
      "outputs": [],
      "source": [
        "id2label = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n",
        "label2id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n",
        "# label2id = {v:k for k, v in id2label.items()}\n",
        "# label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qnRdnMNYgo7A"
      },
      "outputs": [],
      "source": [
        "def collate_fn_orgin(data):\n",
        "    tokens = [i[0] for i in data]\n",
        "    labels = [i[1] for i in data]\n",
        "    #编码\n",
        "    inputs = tokenizer.batch_encode_plus(tokens,\n",
        "                                         truncation=True,\n",
        "                                         padding=True,\n",
        "                                         return_tensors='pt',\n",
        "                                         max_length=512,\n",
        "                                         is_split_into_words=True)\n",
        "    #求一批数据中最长的句子长度\n",
        "    lens = inputs['input_ids'].shape[1]\n",
        "    #在labels的头尾补充7，把所有的labels补充成统一的长度\n",
        "    for i in range(len(labels)):\n",
        "        labels[i] = [7] + labels[i]\n",
        "        labels[i] += [7] * lens\n",
        "        labels[i] = labels[i][:lens]\n",
        "    #把编码结果移动到计算设备\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = v.to(device)\n",
        "    #把统一长度的labels组装成矩阵，并移动到计算设备\n",
        "    labels = torch.LongTensor(labels).to(device)\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gKBUlz-hQzB",
        "outputId": "57f149a8-453b-4f04-d934-acbf785e1fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids torch.Size([2, 37]) tensor([[ 101, 3862, 7157, 3683, 6612, 1765, 4157, 1762, 1336, 7305,  680, 7032,\n",
            "         7305,  722, 7313, 4638, 3862, 1818,  511,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0],\n",
            "        [ 101, 6821, 2429,  898, 2255,  988, 3717, 4638, 1300, 4289, 7667, 4507,\n",
            "         1744, 1079,  671, 3837, 4638, 6392, 6369, 2360,  712, 2898, 6392, 6369,\n",
            "         8024, 3146,  702, 2456, 5029, 5408, 5125, 5401, 5445, 2612, 2131,  511,\n",
            "          102]], device='cuda:0')\n",
            "token_type_ids torch.Size([2, 37]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
            "attention_mask torch.Size([2, 37]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
            "labels torch.Size([2, 37]) tensor([[7, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7,\n",
            "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
            "        [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    ([\n",
        "        '海', '钓', '比', '赛', '地', '点', '在', '厦', '门', '与', '金', '门', '之', '间',\n",
        "        '的', '海', '域', '。'\n",
        "    ], [0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0]),\n",
        "    ([\n",
        "        '这', '座', '依', '山', '傍', '水', '的', '博', '物', '馆', '由', '国', '内', '一',\n",
        "        '流', '的', '设', '计', '师', '主', '持', '设', '计', '，', '整', '个', '建', '筑',\n",
        "        '群', '精', '美', '而', '恢', '宏', '。'\n",
        "    ], [\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
        "    ]),\n",
        "]\n",
        "#试算\n",
        "inputs, labels = collate_fn_orgin(data)\n",
        "for k, v in inputs.items():\n",
        "    print(k, v.shape, v)\n",
        "print('labels', labels.shape, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyN_AjdfkDGf",
        "outputId": "23ac054c-e384-4530-8423-bf3f5a2ba423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': ['5', '6', '7'], 'tokens': [['克', '马', '尔', '的', '女', '儿', '让', '娜', '今', '年', '读', '五', '年', '级', '，', '她', '所', '在', '的', '班', '上', '有', '3', '0', '多', '名', '同', '学', '，', '该', '班', '的', '“', '家', '委', '会', '”', '由', '1', '0', '名', '家', '长', '组', '成', '。'], ['参', '加', '步', '行', '的', '有', '男', '有', '女', '，', '有', '年', '轻', '人', '，', '也', '有', '中', '年', '人', '。'], ['沙', '特', '队', '教', '练', '佩', '雷', '拉', '：', '两', '支', '队', '都', '想', '胜', '，', '因', '此', '都', '作', '出', '了', '最', '大', '的', '努', '力', '。']], 'ner_tags': [[1, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 4, 4, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train'][5:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "9CErqPU1jVjB"
      },
      "outputs": [],
      "source": [
        "def collate_fn(data):\n",
        "    tokens, labels  = [], []\n",
        "    for sample in data:\n",
        "        if not sample['tokens']:\n",
        "            continue\n",
        "        tokens.append(sample['tokens'])\n",
        "        labels.append(sample['ner_tags'])\n",
        "\n",
        "    # tokens = data['tokens']\n",
        "    # labels = data['ner_tags']\n",
        "\n",
        "    #编码\n",
        "    inputs = tokenizer.batch_encode_plus(tokens,\n",
        "                                         truncation=True,\n",
        "                                         padding=True,\n",
        "                                         return_tensors='pt',\n",
        "                                         max_length=512,\n",
        "                                         is_split_into_words=True)\n",
        "    #求一批数据中最长的句子长度\n",
        "    lens = inputs['input_ids'].shape[1]\n",
        "    #在labels的头尾补充7，把所有的labels补充成统一的长度\n",
        "    for i in range(len(labels)):\n",
        "        labels[i] = [-100] + labels[i]\n",
        "        labels[i] += [-100] * lens\n",
        "        labels[i] = labels[i][:lens]\n",
        "    #把编码结果移动到计算设备\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = v.to(device)\n",
        "    #把统一长度的labels组装成矩阵，并移动到计算设备\n",
        "    labels = torch.LongTensor(labels).to(device)\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "j3w_2YoIkQ7S"
      },
      "outputs": [],
      "source": [
        "x, y = collate_fn([\n",
        "    {'id': '3',\n",
        " 'tokens': [],\n",
        " 'ner_tags': [],\n",
        " 'sentence': '海钓比赛地点在厦门与金门之间的海域。'},\n",
        "    {'id': '0',\n",
        " 'tokens': ['海','钓','比','赛','地','点','在','厦','门','与','金','门','之','间','的','海','域','。'],\n",
        " 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0],\n",
        " 'sentence': '海钓比赛地点在厦门与金门之间的海域。'},\n",
        "    {'id': '1',\n",
        " 'tokens': ['海','钓','比','赛','地','点','在','厦','门','与','金','门',],\n",
        " 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6],\n",
        " 'sentence': '海钓比赛地点在厦门与金门'},\n",
        "    {'id': '58',\n",
        " 'tokens': ['如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。','如','果','世','界','油','价','今','后','几','年','内','仍','然','处','于','目','前','的','低','迷','状','态','，','挪','威','政','府','的','财','政','收','入','将','因','此','减','少','至','少','2','5','0','亿','挪','威','克',\n",
        "  '朗','。'],\n",
        " 'ner_tags': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "              0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
        " 'sentence': '如果世界油价今后几年内仍然处于目前的低迷状态，挪威政府的财政收入将因此减少至少250亿挪威克朗。'}\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR5yw9COriC9",
        "outputId": "0072fac6-4a46-47d8-8bc5-663b4f9736cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids : torch.Size([3, 512]) : tensor([[ 101, 3862, 7157,  ...,    0,    0,    0],\n",
            "        [ 101, 3862, 7157,  ...,    0,    0,    0],\n",
            "        [ 101, 1963, 3362,  ..., 6568, 3124,  102]])\n",
            "token_type_ids : torch.Size([3, 512]) : tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "attention_mask : torch.Size([3, 512]) : tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "for k,v in x.items():\n",
        "  print(k, ':', v.shape, ':', v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JqFPL3vsjmX",
        "outputId": "409ee2a7-9314-4ca4-da1a-a89d81fea41b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 512]),\n",
              " tensor([[-100,    0,    0,  ..., -100, -100, -100],\n",
              "         [-100,    0,    0,  ..., -100, -100, -100],\n",
              "         [-100,    0,    0,  ...,    0,    0,    0]]))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47JxTBDlMni",
        "outputId": "9e28cf70-33a4-4565-f636-19d42f6f9397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "             5,    6,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "             0, -100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CGvGiq7QFuNt"
      },
      "outputs": [],
      "source": [
        "dataset_map = dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MfB-8cJlb3s",
        "outputId": "45742c79-5982-4fee-afaa-0d57453153af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 20865\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 2319\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 4637\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Fk5549LaFwEN"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset_map['validation'], batch_size=4, shuffle=True, collate_fn=collate_fn, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Cu2GIUYfwjbj"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for ind, (batch, y) in enumerate(train_dataloader):\n",
        "    try:\n",
        "      i+=1\n",
        "    except:\n",
        "      print(ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "s0JDbs4kPRSU"
      },
      "outputs": [],
      "source": [
        "valid_dataloader = DataLoader(dataset_map['test'], batch_size=4, collate_fn=collate_fn, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si5WcDTXltwK",
        "outputId": "76745de5-7118-46e8-838e-4ba88c821dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 一 旦 冲 洗 过 程 中 出 现 意 外 ， 使 消 费 者 能 从 保 险 公 司 得 到 相 应 的 补 偿 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    3,    4,    4,    4,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
            "       device='cuda:0')\n",
            "input_ids torch.Size([4, 72])\n",
            "token_type_ids torch.Size([4, 72])\n",
            "attention_mask torch.Size([4, 72])\n"
          ]
        }
      ],
      "source": [
        "for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "    break\n",
        "print(tokenizer.decode(inputs['input_ids'][0]))\n",
        "print(labels[0])\n",
        "for k, v in inputs.items():\n",
        "    print(k, v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "16e96c3bb76b46be87a625998ff9076c",
            "6ab0df3ba53e4791990f95c1a2936130",
            "a718d0a1bb6b41be93dcc817472d3f43",
            "caf7af5a108b45298c0064c34450c7b2",
            "36ab9baa2d344ae68ff64a73662f77fb",
            "0801be1ae369464c9c4bb5707f077b09",
            "282e386056354a949485ee336c80f085",
            "fa0bce7220f64fe9b4c76ec10779f211",
            "17df221428e341359cc18f3a6fc53185",
            "80997242f67a4885a190611556d33053",
            "93810da730a74212b5478c2b143adbd7"
          ]
        },
        "id": "CF9sDB-O7-rZ",
        "outputId": "14aea98c-8a70-4b0c-b092-9edba803c997"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16e96c3bb76b46be87a625998ff9076c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-chinese\", num_labels=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JST3gNPIdeMd",
        "outputId": "8d93abda-3209-4a2f-ec2e-863ca5ad7e0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvLyzXWt0HE2",
        "outputId": "63d37f89-86bf-440d-93e1-937b0fe6e6fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 定义优化器和损失函数\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csjYeAGyT0GM",
        "outputId": "e4731fc8-1e64-47f0-96bb-369d19164152"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 Train: 100%|██████████| 579/579 [36:24<00:00,  3.77s/it]\n",
            "Epoch 1 Eval: 100%|██████████| 1159/1159 [20:04<00:00,  1.04s/it]\n"
          ]
        }
      ],
      "source": [
        "# 训练模型\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "for epoch in range(1):\n",
        "    # 训练\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    for batch, y in tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Train\"):\n",
        "        inputs = batch\n",
        "        labels = y\n",
        "        outputs = model(**inputs)\n",
        "        loss = loss_fn(outputs.logits.view(-1, 7), labels.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        epoch_train_loss += loss.item()\n",
        "    train_losses.append(epoch_train_loss / len(train_dataloader))\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    epoch_eval_loss = 0\n",
        "    for batch, y in tqdm(valid_dataloader, desc=f\"Epoch {epoch+1} Eval\"):\n",
        "        inputs = batch\n",
        "        labels = y\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs.logits.view(-1, 7), labels.view(-1))\n",
        "            epoch_eval_loss += loss.item()\n",
        "    eval_losses.append(epoch_eval_loss / len(valid_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZO2grMqIygM",
        "outputId": "66ab2025-c3d5-4f55-c7fb-93adadf5ee94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0.04953076240918085], [0.09511156810561375])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_losses, train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "quPegYZ2xe8g",
        "outputId": "7ec08da0-91a8-4951-d93f-35ccd30872ab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/YElEQVR4nO3de1yUZf7/8fdwGkBFVBTEE6VueLY8hWV2QMFMxUzNLA+5uaZ0It3SzENuawc1XStdK83aNc3WyM1DIuV3UzHzmOYha1MzBTxkqBgQXL8//DHbxICIwwx6v56PxzzWuea67/lcn8bl7X1gbMYYIwAAAAvx8XYBAAAAnkYAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAiqAIUOGKCoqqkzbTpo0STabzb0FVTAHDx6UzWbT22+/7e1SihUVFaUhQ4Z45b2vhP4AFQ0BCCiBzWYr1WPdunXeLhWS1q1bV+J/p8WLF3u7xMuyaNEizZw509tlOBkyZIgqV67s7TKAS+bn7QKAiuzdd991ev7OO+8oJSWlyHiTJk0u633eeOMNFRQUlGnb8ePH6+mnn76s97/aPProo2rXrl2R8ZiYGC9U4z6LFi3S7t279fjjjzuNN2jQQOfPn5e/v793CgOuQAQgoAT333+/0/NNmzYpJSWlyPjvZWdnKzg4uNTvczk/uPz8/OTnx1/l3+rUqZPuueceb5fhMTabTYGBgd4uA7iicAoMuEy33nqrmjdvrq1bt+qWW25RcHCwxo0bJ0n66KOP1L17d0VGRsput6thw4aaMmWK8vPznfbx+2uACq/pmDZtmubNm6eGDRvKbrerXbt2+vLLL522dXUNkM1mU2JiopKTk9W8eXPZ7XY1a9ZMq1evLlL/unXr1LZtWwUGBqphw4b6+9//Xurrij7//HP17dtX9evXl91uV7169fTEE0/o/PnzRdZXuXJl/fjjj0pISFDlypVVs2ZNjR49ukgvTp8+rSFDhqhq1aoKDQ3V4MGDdfr06YvWcimaN2+u2267rch4QUGB6tSp4xSepk2bpo4dO6pGjRoKCgpSmzZt9MEHH1z0PYrr4dtvvy2bzaaDBw86xkrzObn11lu1YsUKHTp0yHFKr/AzU9w1QJ9++qk6deqkSpUqKTQ0VL169dLevXtd1vntt99qyJAhCg0NVdWqVTV06FBlZ2dfdJ2ltXTpUrVp00ZBQUEKCwvT/fffrx9//NFpTnp6uoYOHaq6devKbrerdu3a6tWrl1OvtmzZori4OIWFhSkoKEjXXHONHnzwQbfVCevgn42AG5w8eVLdunXTvffeq/vvv1/h4eGSLvywq1y5spKSklS5cmV9+umnmjBhgrKysvTyyy9fdL+LFi3SmTNn9Kc//Uk2m00vvfSS7r77bv33v/+96FGj9evXa9myZRo5cqSqVKmiv/3tb+rTp48OHz6sGjVqSJK2b9+u+Ph41a5dW5MnT1Z+fr6ee+451axZs1TrXrp0qbKzs/Xwww+rRo0a2rx5s2bPnq0jR45o6dKlTnPz8/MVFxenDh06aNq0aVq7dq2mT5+uhg0b6uGHH5YkGWPUq1cvrV+/XiNGjFCTJk304YcfavDgwaWqp9CZM2d04sSJIuM1atSQzWZT//79NWnSJKWnpysiIsKpZ0ePHtW9997rGJs1a5Z69uypgQMHKjc3V4sXL1bfvn318ccfq3v37pdUV3FK8zl55pln9PPPP+vIkSN65ZVXJKnEa2/Wrl2rbt266dprr9WkSZN0/vx5zZ49WzfddJO2bdtW5KL7fv366ZprrtHUqVO1bds2vfnmm6pVq5ZefPFFt6xv6NChateunaZOnaqMjAzNmjVLGzZs0Pbt2xUaGipJ6tOnj77++ms98sgjioqKUmZmplJSUnT48GHH865du6pmzZp6+umnFRoaqoMHD2rZsmWXXSMsyAAotVGjRpnf/7Xp3LmzkWTmzp1bZH52dnaRsT/96U8mODjY/PLLL46xwYMHmwYNGjief//990aSqVGjhjl16pRj/KOPPjKSzL///W/H2MSJE4vUJMkEBASYb7/91jG2c+dOI8nMnj3bMdajRw8THBxsfvzxR8fYgQMHjJ+fX5F9uuJqfVOnTjU2m80cOnTIaX2SzHPPPec09/rrrzdt2rRxPE9OTjaSzEsvveQY+/XXX02nTp2MJLNgwYIS6/nss8+MpGIfx44dM8YYs3///iK9MMaYkSNHmsqVKzut6/drzM3NNc2bNze3336703iDBg3M4MGDHc9d/XcxxpgFCxYYSeb7778v9j2Mcf056d69u9PnpFDh5+W3/WndurWpVauWOXnypGNs586dxsfHxwwaNKhInQ8++KDTPnv37m1q1KhR5L1+b/DgwaZSpUrFvp6bm2tq1aplmjdvbs6fP+8Y//jjj40kM2HCBGOMMT/99JORZF5++eVi9/Xhhx8aSebLL7+8aF3AxXAKDHADu92uoUOHFhkPCgpy/LnwqESnTp2UnZ2tffv2XXS//fv3V7Vq1RzPO3XqJEn673//e9FtY2Nj1bBhQ8fzli1bKiQkxLFtfn6+1q5dq4SEBEVGRjrmNWrUSN26dbvo/iXn9Z07d04nTpxQx44dZYzR9u3bi8wfMWKE0/NOnTo5rWXlypXy8/NzHBGSJF9fXz3yyCOlqqfQhAkTlJKSUuRRvXp1SdIf/vAHtW7dWkuWLHFsk5+frw8++EA9evRwWtdv//zTTz/p559/VqdOnbRt27ZLqqkkl/s5+b1jx45px44dGjJkiGPN0oXPQJcuXbRy5coi27j6b3Py5EllZWVd8vv/1pYtW5SZmamRI0c6XafUvXt3RUdHa8WKFZIu9CAgIEDr1q3TTz/95HJfhUeKPv74Y+Xl5V1WXQABCHCDOnXqKCAgoMj4119/rd69e6tq1aoKCQlRzZo1HRdQ//zzzxfdb/369Z2eF4ah4n5AlLRt4faF22ZmZur8+fNq1KhRkXmuxlw5fPiw44ds4XU9nTt3llR0fYGBgUVOrf22Hkk6dOiQateuXeTUznXXXVeqegq1aNFCsbGxRR6//W/Uv39/bdiwwXEdyrp165SZman+/fs77evjjz/WjTfeqMDAQFWvXl01a9bUnDlzSvXfr7Qu93Pye4cOHZLkum9NmjTRiRMndO7cOafxy/mslbWW6Ohox+t2u10vvviiVq1apfDwcN1yyy166aWXlJ6e7pjfuXNn9enTR5MnT1ZYWJh69eqlBQsWKCcn57JqhDURgAA3+O2/4AudPn1anTt31s6dO/Xcc8/p3//+t1JSUhzXVJTmtndfX1+X48aYct22NPLz89WlSxetWLFCTz31lJKTk5WSkuK4EPf36yuuHm/p37+/jDGOa5Xef/99Va1aVfHx8Y45n3/+uXr27KnAwEC9/vrrWrlypVJSUnTfffddtI/FXUTu6qLvy/2cuEN5f15K4/HHH9c333yjqVOnKjAwUM8++6yaNGniOJpos9n0wQcfKC0tTYmJifrxxx/14IMPqk2bNjp79qzH6sTVgYuggXKybt06nTx5UsuWLdMtt9ziGP/++++9WNX/1KpVS4GBgfr222+LvOZq7Pd27dqlb775RgsXLtSgQYMc4ykpKWWuqUGDBkpNTdXZs2edjgLt37+/zPsszjXXXKP27dtryZIlSkxM1LJly5SQkCC73e6Y869//UuBgYH65JNPnMYXLFhw0f0XHkE5ffq049SN9L8jIoUu5XNS2t/43aBBA0mu+7Zv3z6FhYWpUqVKpdrX5fptLbfffrvTa/v373e8Xqhhw4Z68skn9eSTT+rAgQNq3bq1pk+frn/84x+OOTfeeKNuvPFGPf/881q0aJEGDhyoxYsX649//GP5LwhXDY4AAeWk8F/Uv/0XdG5url5//XVvleTE19dXsbGxSk5O1tGjRx3j3377rVatWlWq7SXn9RljNGvWrDLXdOedd+rXX3/VnDlzHGP5+fmaPXt2mfdZkv79+2vTpk2aP3++Tpw4UeT0l6+vr2w2m9NRm4MHDyo5Ofmi+y68/uo///mPY+zcuXNauHBhkfeQSvc5qVSpUqlOidWuXVutW7fWwoULnX6FwO7du7VmzRrdeeedF92Hu7Rt21a1atXS3LlznU5VrVq1Snv37nXcSZedna1ffvnFaduGDRuqSpUqju1++umnIkekWrduLUmcBsMl4wgQUE46duyoatWqafDgwXr00Udls9n07rvvevSUwsVMmjRJa9as0U033aSHH35Y+fn5evXVV9W8eXPt2LGjxG2jo6PVsGFDjR49Wj/++KNCQkL0r3/967KuGenRo4duuukmPf300zp48KCaNm2qZcuWXfJ1MJ9//nmRH6bShYuAW7Zs6Xjer18/jR49WqNHj1b16tUVGxvrNL979+6aMWOG4uPjdd999ykzM1OvvfaaGjVqpK+++qrEGrp27ar69etr2LBhGjNmjHx9fTV//nzVrFlThw8fdsy7lM9JmzZttGTJEiUlJaldu3aqXLmyevTo4fL9X375ZXXr1k0xMTEaNmyY4zb4qlWratKkSSXWfqny8vL0l7/8pch49erVNXLkSL344osaOnSoOnfurAEDBjhug4+KitITTzwhSfrmm290xx13qF+/fmratKn8/Pz04YcfKiMjw/FrCRYuXKjXX39dvXv3VsOGDXXmzBm98cYbCgkJ8Wiow1XCK/eeAVeo4m6Db9asmcv5GzZsMDfeeKMJCgoykZGR5s9//rP55JNPjCTz2WefOeYVdxu8q1uCJZmJEyc6nhd3G/yoUaOKbPv7W7WNMSY1NdVcf/31JiAgwDRs2NC8+eab5sknnzSBgYHFdOF/9uzZY2JjY03lypVNWFiYeeihhxy32//2luzibpV2VfvJkyfNAw88YEJCQkzVqlXNAw88YLZv3+6W2+B/27dCN910k5Fk/vjHP7rc51tvvWUaN25s7Ha7iY6ONgsWLHBZt6vebt261XTo0MEEBASY+vXrmxkzZri8Db60n5OzZ8+a++67z4SGhhpJjs+Mq9vgjTFm7dq15qabbjJBQUEmJCTE9OjRw+zZs8dpTuFajh8/7jTuqk5XCn/FgatHw4YNHfOWLFlirr/+emO320316tXNwIEDzZEjRxyvnzhxwowaNcpER0ebSpUqmapVq5oOHTqY999/3zFn27ZtZsCAAaZ+/frGbrebWrVqmbvuusts2bKlxBoBV2zGVKB/jgKoEBISEvT111/rwIED3i4FAMoF1wABFvf7r604cOCAVq5cqVtvvdU7BQGAB3AECLC42rVra8iQIbr22mt16NAhzZkzRzk5Odq+fbsaN27s7fIAoFxwETRgcfHx8XrvvfeUnp4uu92umJgY/fWvfyX8ALiqcQQIAABYDtcAAQAAyyEAAQAAy+EaIBcKCgp09OhRValSpdS/eh4AAHiXMUZnzpxRZGSkfHxKPsZDAHLh6NGjqlevnrfLAAAAZfDDDz+obt26Jc4hALlQpUoVSRcaGBIS4uVqvC8vL09r1qxR165d5e/v7+1yrlr02TPos2fQZ8+gz86ysrJUr149x8/xkhCAXCg87RUSEkIA0oW/YMHBwQoJCeEvWDmiz55Bnz2DPnsGfXatNJevcBE0AACwHAIQAACwHAIQAACwHK4BAgDAQwoKCpSbm+u2/eXl5cnPz0+//PKL8vPz3bbfisrf31++vr5u2RcBCAAAD8jNzdX333+vgoICt+3TGKOIiAj98MMPlvm9daGhoYqIiLjs9RKAAAAoZ8YYHTt2TL6+vqpXr95Ff0lfaRUUFOjs2bOqXLmy2/ZZURljlJ2drczMTElS7dq1L2t/BCAAAMrZr7/+quzsbEVGRio4ONht+y08pRYYGHjVByBJCgoKkiRlZmaqVq1al3U67OrvFgAAXlZ4fU5AQICXK7nyFQbIvLy8y9oPAQgAAA+xynU65cldPSQAAQAAyyEAAQAAj4mKitLMmTO9XQYBCAAAFGWz2Up8TJo0qUz7/fLLLzV8+HD3FlsG3AUGAACKOHbsmOPPS5Ys0YQJE7R//37HWOXKlR1/NsYoPz9ffn4XjxU1a9Z0b6FlxBEgAABQREREhONRtWpV2Ww2x/N9+/apSpUqWrVqldq0aSO73a7169fru+++U69evRQeHq7KlSurXbt2Wrt2rdN+f38KzGaz6c0331Tv3r0VHBysxo0ba/ny5eW+PgIQAAAeZoxRdu6vbnmcz82/pPnGGLet4+mnn9YLL7ygvXv3qmXLljp79qzuvPNOpaamavv27YqPj1ePHj10+PDhEvczefJk9evXT1999ZXuvPNODRw4UKdOnXJbna5wCgwAAA87n5evphM+8cp773kuTsEB7vnx/9xzz6lLly6O59WrV1erVq0cz6dMmaIPP/xQy5cvV2JiYrH7GTJkiAYMGCBJ+utf/6q//e1v2rx5s+Lj491SpyscAQIAAGXStm1bp+dnz57V6NGj1aRJE4WGhqpy5crau3fvRY8AtWzZ0vHnSpUqKSQkxPGVF+WFI0AAAHhYkL+v9jwXd9n7KSgo0JmsM6oSUqXUX4UR5O+eb1OXLoSV3xo9erRSUlI0bdo0NWrUSEFBQbrnnnuUm5tb4n78/f2dnttsNrd+aawrBCAAADzMZrO55TRUQUGBfg3wVXCAX4X4LrANGzZoyJAh6t27t6QLR4QOHjzo3aKK4f1uAQCAq0Ljxo21bNky7dixQzt37tR9991X7kdyyooABAAA3GLGjBmqVq2aOnbsqB49eiguLk433HCDt8tyiVNgAACgREOGDNGQIUMcz2+99VaXt9NHRUXp008/dRobNWqU0/PfnxJztZ/Tp0+XudbS4ggQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAACwHAIQAADwioMHD8pms2nHjh0ef28CEAAAcGnIkCGy2WxFHvHx8d4u7bLxXWAAAKBY8fHxWrBggdOY3W73UjXuwxEgAABQLLvdroiICKdHtWrVdN9996l///5Oc/Py8hQWFqZ33nlHkrR69WrdfPPNCg0NVY0aNXTXXXfpu+++88YyiuAIEAAAnmaMlJd9+fspKLiwn1xfyaeUxzT8gyWb7bLfeuDAgerbt6/Onj2rypUrS5I++eQTZWdnq3fv3pKkc+fOKSkpSS1bttTZs2c1YcIE9e7dWzt27JBPaestJwQgAAA8LS9b+mvkZe/GR1LopW407qgUUKnU0z/++GNHwHHsYtw4/fnPf1alSpX04Ycf6oEHHpAkLVq0SD179lSVKlUkSX369HHabv78+apZs6b27Nmj5s2bX2rlbkUAAgAAxbrttts0Z84cp7Hq1avLz89P/fr10z//+U898MADOnfunD766CMtXrzYMe/AgQOaMGGCvvjiC504cUIFBQWSpMOHDxOAAACwHP/gC0diLlNBQYGyzpxRSJUqpT+l5B98Se9RqVIlNWrUyOVrAwcOVOfOnZWZmamUlBQFBQU53SHWo0cPNWjQQG+88YYiIyNVUFCg5s2bKzc395JqKA8EIAAAPM1mu6TTUMUqKJD88y/sywvX1HTs2FH16tXTkiVLtGrVKvXt21f+/v6SpJMnT2r//v1644031KlTJ0nS+vXrPV5jcQhAAACgWDk5OUpPT3ca8/PzU1hYmCTpvvvu09y5c/XNN9/os88+c8ypVq2aatSooXnz5ql27do6fPiwnn76aY/WXhJugwcAAMVavXq1ateu7fS4+eabHa8PHDhQe/bsUZ06dXTTTTc5xn18fLR48WJt3bpVzZs31xNPPKGXX37ZG0twiSNAAADApbfffltvv/12iXOaNGkiY4zL12JjY7Vnzx6nsd/OjYqKKnbb8sYRIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDleD0CvvfaaoqKiFBgYqA4dOmjz5s0lzl+6dKmio6MVGBioFi1aaOXKlU6vZ2RkaMiQIYqMjFRwcLDi4+N14MCB8lwCAACl4q0Lfq8m7uqhVwPQkiVLlJSUpIkTJ2rbtm1q1aqV4uLilJmZ6XL+xo0bNWDAAA0bNkzbt29XQkKCEhIStHv3bkkXmpKQkKD//ve/+uijj7R9+3Y1aNBAsbGxOnfunCeXBgCAg6+vryRViN+AfKXLzr7wJbKFv3CxrLx6G/yMGTP00EMPaejQoZKkuXPnasWKFZo/f77LX5Y0a9YsxcfHa8yYMZKkKVOmKCUlRa+++qrmzp2rAwcOaNOmTdq9e7eaNWsmSZozZ44iIiL03nvv6Y9//KPnFgcAwP/n5+en4OBgHT9+XP7+/m77JvSCggLl5ubql19+8fq3q5c3Y4yys7OVmZmp0NBQR6gsK68FoNzcXG3dulVjx451jPn4+Cg2NlZpaWkut0lLS1NSUpLTWFxcnJKTkyVd+G2VkhQYGOi0T7vdrvXr1xOAAABeYbPZVLt2bX3//fc6dOiQ2/ZrjNH58+cVFBQkm83mtv1WZKGhoYqIiLjs/XgtAJ04cUL5+fkKDw93Gg8PD9e+fftcbpOenu5yfuGv6I6Ojlb9+vU1duxY/f3vf1elSpX0yiuv6MiRIzp27FixteTk5DjCkyRlZWVJkvLy8pSXl1em9V1NCntAL8oXffYM+uwZ9Lkom82mqKgo5eXlue06ll9//VUbN25Ux44d5ed3df9uY5vNJj8/P/n6+urXX391OedSPm9XVbf8/f21bNkyDRs2TNWrV5evr69iY2PVrVu3Ej9sU6dO1eTJk4uMr1mzRsHBl/atuVezlJQUb5dgCfTZM+izZ9Bnz/jPf/7j7RIqhMLrg0rDawEoLCxMvr6+ysjIcBrPyMgo9tBWRETERee3adNGO3bs0M8//6zc3FzVrFlTHTp0UNu2bYutZezYsU6n1rKyslSvXj117dpVISEhZVneVSUvL08pKSnq0qXLZV90huLRZ8+gz55Bnz2DPjsrPINTGl4LQAEBAWrTpo1SU1OVkJAg6cLFXKmpqUpMTHS5TUxMjFJTU/X44487xlJSUhQTE1NkbtWqVSVJBw4c0JYtWzRlypRia7Hb7bLb7UXG/f39+UD9Bv3wDPrsGfTZM+izZ9DnCy6lB149BZaUlKTBgwerbdu2at++vWbOnKlz58457gobNGiQ6tSpo6lTp0qSHnvsMXXu3FnTp09X9+7dtXjxYm3ZskXz5s1z7HPp0qWqWbOm6tevr127dumxxx5TQkKCunbt6pU1AgCAiserAah///46fvy4JkyYoPT0dLVu3VqrV692XOh8+PBhp9v6OnbsqEWLFmn8+PEaN26cGjdurOTkZDVv3twx59ixY0pKSlJGRoZq166tQYMG6dlnn/X42gAAQMXl9YugExMTiz3ltW7duiJjffv2Vd++fYvd36OPPqpHH33UXeUBAICr0NX9W5MAAABcIAABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADL8XoAeu211xQVFaXAwEB16NBBmzdvLnH+0qVLFR0drcDAQLVo0UIrV650ev3s2bNKTExU3bp1FRQUpKZNm2ru3LnluQQAAHCF8WoAWrJkiZKSkjRx4kRt27ZNrVq1UlxcnDIzM13O37hxowYMGKBhw4Zp+/btSkhIUEJCgnbv3u2Yk5SUpNWrV+sf//iH9u7dq8cff1yJiYlavny5p5YFAAAqOK8GoBkzZuihhx7S0KFDHUdqgoODNX/+fJfzZ82apfj4eI0ZM0ZNmjTRlClTdMMNN+jVV191zNm4caMGDx6sW2+9VVFRURo+fLhatWp10SNLAADAOvy89ca5ubnaunWrxo4d6xjz8fFRbGys0tLSXG6TlpampKQkp7G4uDglJyc7nnfs2FHLly/Xgw8+qMjISK1bt07ffPONXnnllWJrycnJUU5OjuN5VlaWJCkvL095eXllWd5VpbAH9KJ80WfPoM+eQZ89gz47u5Q+eC0AnThxQvn5+QoPD3caDw8P1759+1xuk56e7nJ+enq64/ns2bM1fPhw1a1bV35+fvLx8dEbb7yhW265pdhapk6dqsmTJxcZX7NmjYKDgy9lWVe1lJQUb5dgCfTZM+izZ9Bnz6DPF2RnZ5d6rtcCUHmZPXu2Nm3apOXLl6tBgwb6z3/+o1GjRikyMlKxsbEutxk7dqzTkaWsrCzVq1dPXbt2VUhIiKdKr7Dy8vKUkpKiLl26yN/f39vlXLXos2fQZ8+gz55Bn50VnsEpDa8FoLCwMPn6+iojI8NpPCMjQxERES63iYiIKHH++fPnNW7cOH344Yfq3r27JKlly5basWOHpk2bVmwAstvtstvtRcb9/f35QP0G/fAM+uwZ9Nkz6LNn0OcLLqUHXrsIOiAgQG3atFFqaqpjrKCgQKmpqYqJiXG5TUxMjNN86cJhv8L5hdfs+Pg4L8vX11cFBQVuXgEAALhSefUUWFJSkgYPHqy2bduqffv2mjlzps6dO6ehQ4dKkgYNGqQ6depo6tSpkqTHHntMnTt31vTp09W9e3ctXrxYW7Zs0bx58yRJISEh6ty5s8aMGaOgoCA1aNBA//d//6d33nlHM2bM8No6AQBAxeLVANS/f38dP35cEyZMUHp6ulq3bq3Vq1c7LnQ+fPiw09Gcjh07atGiRRo/frzGjRunxo0bKzk5Wc2bN3fMWbx4scaOHauBAwfq1KlTatCggZ5//nmNGDHC4+sDAAAVk9cvgk5MTFRiYqLL19atW1dkrG/fvurbt2+x+4uIiNCCBQvcVR4AALgKef2rMAAAADyNAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACyHAAQAACynTAHohx9+0JEjRxzPN2/erMcff1zz5s1zW2EAAADlpUwB6L777tNnn30mSUpPT1eXLl20efNmPfPMM3ruuefcWiAAAIC7lSkA7d69W+3bt5ckvf/++2revLk2btyof/7zn3r77bfdWR8AAIDblSkA5eXlyW63S5LWrl2rnj17SpKio6N17Ngx91UHAABQDsoUgJo1a6a5c+fq888/V0pKiuLj4yVJR48eVY0aNdxaIAAAgLuVKQC9+OKL+vvf/65bb71VAwYMUKtWrSRJy5cvd5waAwAAqKj8yrLRrbfeqhMnTigrK0vVqlVzjA8fPlzBwcFuKw4AAKA8lOkI0Pnz55WTk+MIP4cOHdLMmTO1f/9+1apVy60FAgAAuFuZAlCvXr30zjvvSJJOnz6tDh06aPr06UpISNCcOXPcWiAAAIC7lSkAbdu2TZ06dZIkffDBBwoPD9ehQ4f0zjvv6G9/+5tbCwQAAHC3MgWg7OxsValSRZK0Zs0a3X333fLx8dGNN96oQ4cOubVAAAAAdytTAGrUqJGSk5P1ww8/6JNPPlHXrl0lSZmZmQoJCXFrgQAAAO5WpgA0YcIEjR49WlFRUWrfvr1iYmIkXTgadP3117u1QAAAAHcr023w99xzj26++WYdO3bM8TuAJOmOO+5Q79693VYcAABAeShTAJKkiIgIRUREOL4Vvm7duvwSRAAAcEUo0ymwgoICPffcc6pataoaNGigBg0aKDQ0VFOmTFFBQYG7awQAAHCrMh0BeuaZZ/TWW2/phRde0E033SRJWr9+vSZNmqRffvlFzz//vFuLBAAAcKcyBaCFCxfqzTffdHwLvCS1bNlSderU0ciRIwlAAACgQivTKbBTp04pOjq6yHh0dLROnTp12UUBAACUpzIFoFatWunVV18tMv7qq6+qZcuWl10UAABAeSrTKbCXXnpJ3bt319q1ax2/AygtLU0//PCDVq5c6dYCAQAA3K1MR4A6d+6sb775Rr1799bp06d1+vRp3X333fr666/17rvvurtGAAAAtyrz7wGKjIwscrHzzp079dZbb2nevHmXXRgAAEB5KdMRIAAAgCsZAQgAAFhOhQhAr732mqKiohQYGKgOHTpo8+bNJc5funSpoqOjFRgYqBYtWhS58Npms7l8vPzyy+W5DAAAcIW4pGuA7r777hJfP3369CUXsGTJEiUlJWnu3Lnq0KGDZs6cqbi4OO3fv1+1atUqMn/jxo0aMGCApk6dqrvuukuLFi1SQkKCtm3bpubNm0uSjh075rTNqlWrNGzYMPXp0+eS6wMAAFefSzoCVLVq1RIfDRo00KBBgy6pgBkzZuihhx7S0KFD1bRpU82dO1fBwcGaP3++y/mzZs1SfHy8xowZoyZNmmjKlCm64YYbnH4vUeEXtRY+PvroI91222269tprL6k2AABwdbqkI0ALFixw65vn5uZq69atGjt2rGPMx8dHsbGxSktLc7lNWlqakpKSnMbi4uKUnJzscn5GRoZWrFihhQsXFltHTk6OcnJyHM+zsrIkSXl5ecrLyyvtcq5ahT2gF+WLPnsGffYM+uwZ9NnZpfShzLfBu8OJEyeUn5+v8PBwp/Hw8HDt27fP5Tbp6eku56enp7ucv3DhQlWpUqXE03dTp07V5MmTi4yvWbNGwcHBF1uGZaSkpHi7BEugz55Bnz2DPnsGfb4gOzu71HO9GoA8Yf78+Ro4cKACAwOLnTN27Fino0pZWVmqV6+eunbtqpCQEE+UWaHl5eUpJSVFXbp0kb+/v7fLuWrRZ8+gz55Bnz2DPjsrPINTGl4NQGFhYfL19VVGRobTeEZGhiIiIlxuExERUer5n3/+ufbv368lS5aUWIfdbpfdbi8y7u/vzwfqN+iHZ9Bnz6DPnkGfPYM+X3ApPfDqbfABAQFq06aNUlNTHWMFBQVKTU11fMfY78XExDjNly4c+nM1/6233lKbNm3UqlUr9xYOAACuaF4/BZaUlKTBgwerbdu2at++vWbOnKlz585p6NChkqRBgwapTp06mjp1qiTpscceU+fOnTV9+nR1795dixcv1pYtW4p8/UZWVpaWLl2q6dOne3xNAACgYvN6AOrfv7+OHz+uCRMmKD09Xa1bt9bq1asdFzofPnxYPj7/O1DVsWNHLVq0SOPHj9e4cePUuHFjJScnO34HUKHFixfLGKMBAwZ4dD0AAKDi83oAkqTExEQlJia6fG3dunVFxvr27au+ffuWuM/hw4dr+PDh7igPAABcZSrEV2EAAAB4EgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYjtcD0GuvvaaoqCgFBgaqQ4cO2rx5c4nzly5dqujoaAUGBqpFixZauXJlkTl79+5Vz549VbVqVVWqVEnt2rXT4cOHy2sJAADgCuPVALRkyRIlJSVp4sSJ2rZtm1q1aqW4uDhlZma6nL9x40YNGDBAw4YN0/bt25WQkKCEhATt3r3bMee7777TzTffrOjoaK1bt05fffWVnn32WQUGBnpqWQAAoILzagCaMWOGHnroIQ0dOlRNmzbV3LlzFRwcrPnz57ucP2vWLMXHx2vMmDFq0qSJpkyZohtuuEGvvvqqY84zzzyjO++8Uy+99JKuv/56NWzYUD179lStWrU8tSwAAFDBeS0A5ebmauvWrYqNjf1fMT4+io2NVVpamstt0tLSnOZLUlxcnGN+QUGBVqxYoT/84Q+Ki4tTrVq11KFDByUnJ5fbOgAAwJXHz1tvfOLECeXn5ys8PNxpPDw8XPv27XO5TXp6usv56enpkqTMzEydPXtWL7zwgv7yl7/oxRdf1OrVq3X33Xfrs88+U+fOnV3uNycnRzk5OY7nWVlZkqS8vDzl5eWVeY1Xi8Ie0IvyRZ89gz57Bn32DPrs7FL64LUAVB4KCgokSb169dITTzwhSWrdurU2btyouXPnFhuApk6dqsmTJxcZX7NmjYKDg8uv4CtMSkqKt0uwBPrsGfTZM+izZ9DnC7Kzs0s912sBKCwsTL6+vsrIyHAaz8jIUEREhMttIiIiSpwfFhYmPz8/NW3a1GlOkyZNtH79+mJrGTt2rJKSkhzPs7KyVK9ePXXt2lUhISGXtK6rUV5enlJSUtSlSxf5+/t7u5yrFn32DPrsGfTZM+izs8IzOKXhtQAUEBCgNm3aKDU1VQkJCZIuHMFJTU1VYmKiy21iYmKUmpqqxx9/3DGWkpKimJgYxz7btWun/fv3O233zTffqEGDBsXWYrfbZbfbi4z7+/vzgfoN+uEZ9Nkz6LNn0GfPoM8XXEoPvHoKLCkpSYMHD1bbtm3Vvn17zZw5U+fOndPQoUMlSYMGDVKdOnU0depUSdJjjz2mzp07a/r06erevbsWL16sLVu2aN68eY59jhkzRv3799ctt9yi2267TatXr9a///1vrVu3zhtLBAAAFZBXA1D//v11/PhxTZgwQenp6WrdurVWr17tuND58OHD8vH5341qHTt21KJFizR+/HiNGzdOjRs3VnJyspo3b+6Y07t3b82dO1dTp07Vo48+quuuu07/+te/dPPNN3t8fQAAoGLy+kXQiYmJxZ7ycnXUpm/fvurbt2+J+3zwwQf14IMPuqM8AABwFfL6V2EAAAB4GgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYToUIQK+99pqioqIUGBioDh06aPPmzSXOX7p0qaKjoxUYGKgWLVpo5cqVTq8PGTJENpvN6REfH1+eSwAAAFcQrwegJUuWKCkpSRMnTtS2bdvUqlUrxcXFKTMz0+X8jRs3asCAARo2bJi2b9+uhIQEJSQkaPfu3U7z4uPjdezYMcfjvffe88RyAADAFcDrAWjGjBl66KGHNHToUDVt2lRz585VcHCw5s+f73L+rFmzFB8frzFjxqhJkyaaMmWKbrjhBr366qtO8+x2uyIiIhyPatWqeWI5AADgCuDnzTfPzc3V1q1bNXbsWMeYj4+PYmNjlZaW5nKbtLQ0JSUlOY3FxcUpOTnZaWzdunWqVauWqlWrpttvv11/+ctfVKNGDZf7zMnJUU5OjuN5VlaWJCkvL095eXllWdpVpbAH9KJ80WfPoM+eQZ89gz47u5Q+eDUAnThxQvn5+QoPD3caDw8P1759+1xuk56e7nJ+enq643l8fLzuvvtuXXPNNfruu+80btw4devWTWlpafL19S2yz6lTp2ry5MlFxtesWaPg4OCyLO2qlJKS4u0SLIE+ewZ99gz67Bn0+YLs7OxSz/VqACov9957r+PPLVq0UMuWLdWwYUOtW7dOd9xxR5H5Y8eOdTqqlJWVpXr16qlr164KCQnxSM0VWV5enlJSUtSlSxf5+/t7u5yrFn32DPrsGfTZM+izs8IzOKXh1QAUFhYmX19fZWRkOI1nZGQoIiLC5TYRERGXNF+Srr32WoWFhenbb791GYDsdrvsdnuRcX9/fz5Qv0E/PIM+ewZ99gz67Bn0+YJL6YFXL4IOCAhQmzZtlJqa6hgrKChQamqqYmJiXG4TExPjNF+6cOivuPmSdOTIEZ08eVK1a9d2T+EAAOCK5vW7wJKSkvTGG29o4cKF2rt3rx5++GGdO3dOQ4cOlSQNGjTI6SLpxx57TKtXr9b06dO1b98+TZo0SVu2bFFiYqIk6ezZsxozZow2bdqkgwcPKjU1Vb169VKjRo0UFxfnlTUCAICKxevXAPXv31/Hjx/XhAkTlJ6ertatW2v16tWOC50PHz4sH5//5bSOHTtq0aJFGj9+vMaNG6fGjRsrOTlZzZs3lyT5+vrqq6++0sKFC3X69GlFRkaqa9eumjJlisvTXAAAwHq8HoAkKTEx0XEE5/fWrVtXZKxv377q27evy/lBQUH65JNP3FkeAAC4ynj9FBgAAICnEYAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlVIhvg69ojDGSpKysLC9XUjHk5eUpOztbWVlZ8vf393Y5Vy367Bn02TPos2fQZ2eFP7cLf46XhADkwpkzZyRJ9erV83IlAADgUp05c0ZVq1YtcY7NlCYmWUxBQYGOHj2qKlWqyGazebscr8vKylK9evX0ww8/KCQkxNvlXLXos2fQZ8+gz55Bn50ZY3TmzBlFRkbKx6fkq3w4AuSCj4+P6tat6+0yKpyQkBD+gnkAffYM+uwZ9Nkz6PP/XOzITyEuggYAAJZDAAIAAJZDAMJF2e12TZw4UXa73dulXNXos2fQZ8+gz55Bn8uOi6ABAIDlcAQIAABYDgEIAABYDgEIAABYDgEIAABYDgEIOnXqlAYOHKiQkBCFhoZq2LBhOnv2bInb/PLLLxo1apRq1KihypUrq0+fPsrIyHA59+TJk6pbt65sNptOnz5dDiu4MpRHn3fu3KkBAwaoXr16CgoKUpMmTTRr1qzyXkqF89prrykqKkqBgYHq0KGDNm/eXOL8pUuXKjo6WoGBgWrRooVWrlzp9LoxRhMmTFDt2rUVFBSk2NhYHThwoDyXcEVwZ5/z8vL01FNPqUWLFqpUqZIiIyM1aNAgHT16tLyXUeG5+/P8WyNGjJDNZtPMmTPdXPUVyMDy4uPjTatWrcymTZvM559/bho1amQGDBhQ4jYjRoww9erVM6mpqWbLli3mxhtvNB07dnQ5t1evXqZbt25Gkvnpp5/KYQVXhvLo81tvvWUeffRRs27dOvPdd9+Zd9991wQFBZnZs2eX93IqjMWLF5uAgAAzf/588/XXX5uHHnrIhIaGmoyMDJfzN2zYYHx9fc1LL71k9uzZY8aPH2/8/f3Nrl27HHNeeOEFU7VqVZOcnGx27txpevbsaa655hpz/vx5Ty2rwnF3n0+fPm1iY2PNkiVLzL59+0xaWppp3769adOmjSeXVeGUx+e50LJly0yrVq1MZGSkeeWVV8p5JRUfAcji9uzZYySZL7/80jG2atUqY7PZzI8//uhym9OnTxt/f3+zdOlSx9jevXuNJJOWluY09/XXXzedO3c2qamplg5A5d3n3xo5cqS57bbb3Fd8Bde+fXszatQox/P8/HwTGRlppk6d6nJ+v379TPfu3Z3GOnToYP70pz8ZY4wpKCgwERER5uWXX3a8fvr0aWO32817771XDiu4Mri7z65s3rzZSDKHDh1yT9FXoPLq85EjR0ydOnXM7t27TYMGDQhAxhhOgVlcWlqaQkND1bZtW8dYbGysfHx89MUXX7jcZuvWrcrLy1NsbKxjLDo6WvXr11daWppjbM+ePXruuef0zjvvXPRL6a525dnn3/v5559VvXp19xVfgeXm5mrr1q1OPfLx8VFsbGyxPUpLS3OaL0lxcXGO+d9//73S09Od5lStWlUdOnQose9Xs/Losys///yzbDabQkND3VL3laa8+lxQUKAHHnhAY8aMUbNmzcqn+CuQtX8qQenp6apVq5bTmJ+fn6pXr6709PRitwkICCjyf1Lh4eGObXJycjRgwAC9/PLLql+/frnUfiUprz7/3saNG7VkyRINHz7cLXVXdCdOnFB+fr7Cw8OdxkvqUXp6eonzC//3UvZ5tSuPPv/eL7/8oqeeekoDBgyw7Jd6llefX3zxRfn5+enRRx91f9FXMALQVerpp5+WzWYr8bFv375ye/+xY8eqSZMmuv/++8vtPSoCb/f5t3bv3q1evXpp4sSJ6tq1q0feE3CHvLw89evXT8YYzZkzx9vlXFW2bt2qWbNm6e2335bNZvN2ORWKn7cLQPl48sknNWTIkBLnXHvttYqIiFBmZqbT+K+//qpTp04pIiLC5XYRERHKzc3V6dOnnY5OZGRkOLb59NNPtWvXLn3wwQeSLtxVI0lhYWF65plnNHny5DKurGLxdp8L7dmzR3fccYeGDx+u8ePHl2ktV6KwsDD5+voWuQPRVY8KRURElDi/8H8zMjJUu3ZtpzmtW7d2Y/VXjvLoc6HC8HPo0CF9+umnlj36I5VPnz///HNlZmY6HYnPz8/Xk08+qZkzZ+rgwYPuXcSVxNsXIcG7Ci/O3bJli2Psk08+KdXFuR988IFjbN++fU4X53777bdm165djsf8+fONJLNx48Zi72a4mpVXn40xZvfu3aZWrVpmzJgx5beACqx9+/YmMTHR8Tw/P9/UqVOnxItG77rrLqexmJiYIhdBT5s2zfH6zz//zEXQbu6zMcbk5uaahIQE06xZM5OZmVk+hV9h3N3nEydOOP1/8a5du0xkZKR56qmnzL59+8pvIVcAAhBMfHy8uf76680XX3xh1q9fbxo3bux0e/aRI0fMddddZ7744gvH2IgRI0z9+vXNp59+arZs2WJiYmJMTExMse/x2WefWfouMGPKp8+7du0yNWvWNPfff785duyY42GlHyaLFy82drvdvP3222bPnj1m+PDhJjQ01KSnpxtjjHnggQfM008/7Zi/YcMG4+fnZ6ZNm2b27t1rJk6c6PI2+NDQUPPRRx+Zr776yvTq1Yvb4N3c59zcXNOzZ09Tt25ds2PHDqfPb05OjlfWWBGUx+f597gL7AICEMzJkyfNgAEDTOXKlU1ISIgZOnSoOXPmjOP177//3kgyn332mWPs/PnzZuTIkaZatWomODjY9O7d2xw7dqzY9yAAlU+fJ06caCQVeTRo0MCDK/O+2bNnm/r165uAgADTvn17s2nTJsdrnTt3NoMHD3aa//7775s//OEPJiAgwDRr1sysWLHC6fWCggLz7LPPmvDwcGO3280dd9xh9u/f74mlVGju7HPh593V47d/B6zI3Z/n3yMAXWAz5v9fnAEAAGAR3AUGAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAMWw2WxKTk72dhkAygEBCECFNGTIENlstiKP+Ph4b5cG4CrAt8EDqLDi4+O1YMECpzG73e6lagBcTTgCBKDCstvtioiIcHpUq1ZN0oXTU3PmzFG3bt0UFBSka6+9Vh988IHT9rt27dLtt9+uoKAg1ahRQ8OHD9fZs2ed5syfP1/NmjWT3W5X7dq1lZiY6PT6iRMn1Lt3bwUHB6tx48Zavny547WffvpJAwcOVM2aNRUUFKTGjRsXCWwAKiYCEIAr1rPPPqs+ffpo586dGjhwoO69917t3btXknTu3DnFxcWpWrVq+vLLL7V06VKtXbvWKeDMmTNHo0aN0vDhw7Vr1y4tX75cjRo1cnqPyZMnq1+/fvrqq6905513auDAgTp16pTj/ffs2aNVq1Zp7969mjNnjsLCwjzXAABl5+1vYwUAVwYPHmx8fX1NpUqVnB7PP/+8McYYSWbEiBFO23To0ME8/PDDxhhj5s2bZ6pVq2bOnj3reH3FihXGx8fHpKenG2OMiYyMNM8880yxNUgy48ePdzw/e/askWRWrVpljDGmR48eZujQoe5ZMACP4hogABXWbbfdpjlz5jiNVa9e3fHnmJgYp9diYmK0Y8cOSdLevXvVqlUrVapUyfH6TTfdpIKCAu3fv182m01Hjx7VHXfcUWINLVu2dPy5UqVKCgkJUWZmpiTp4YcfVp8+fbRt2zZ17dpVCQkJ6tixY5nWCsCzCEAAKqxKlSoVOSXlLkFBQaWa5+/v7/TcZrOpoKBAktStWzcdOnRIK1euVEpKiu644w6NGjVK06ZNc3u9ANyLa4AAXLE2bdpU5HmTJk0kSU2aNNHOnTt17tw5x+sbNmyQj4+PrrvuOlWpUkVRUVFKTU29rBpq1qypwYMH6x//+IdmzpypefPmXdb+AHgGR4AAVFg5OTlKT093GvPz83NcaLx06VK1bdtWN998s/75z39q8+bNeuuttyRJAwcO1MSJEzV48GBNmjRJx48f1yOPPKIHHnhA4eHhkqRJkyZpxIgRqlWrlrp166YzZ85ow4YNeuSRR0pV34QJE9SmTRs1a9ZMOTk5+vjjjx0BDEDFRgACUGGtXr1atWvXdhq77rrrtG/fPkkX7tBavHixRo4cqdq1a+u9995T06ZNJUnBwcH65JNP9Nhjj6ldu3YKDg5Wnz59NGPGDMe+Bg8erF9++UWvvPKKRo8erbCwMN1zzz2lri8gIEBjx47VwYMHFRQUpE6dOmnx4sVuWDmA8mYzxhhvFwEAl8pms+nDDz9UQkKCt0sBcAXiGiAAAGA5BCAAAGA5XAME4IrE2XsAl4MjQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHL+HwxsDSaZXfADAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 绘制训练损失曲线\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(eval_losses, label='Eval')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Evaluation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "twsuUC7bWr4B"
      },
      "outputs": [],
      "source": [
        "# 保存模型 保存的是文件 里面有config.json文件和model.safetensors模型文件\n",
        "model.save_pretrained(\"./peoples_daily_ner_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "wOO1TX3pPeDo"
      },
      "outputs": [],
      "source": [
        "# 推理模型\n",
        "# example_sentence = \"海钓比赛地点在厦门与金门\"\n",
        "example_sentence = \"北京是中国的首都。\"\n",
        "inputs = tokenizer(example_sentence, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "# 部署模型\n",
        "# 你可以使用保存的模型加载并在其他地方使用，例如在Flask或FastAPI中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iucCuyHTXF3n",
        "outputId": "f14a6f26-7f47-456c-ca5c-8118e406c716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TokenClassifierOutput(loss=None, logits=tensor([[[ 5.5332, -2.0215, -2.3632, -1.7335, -1.1529, -0.1443, -0.3947],\n",
              "         [-2.0747, -1.8169, -2.6177,  0.3363, -2.5047,  5.4459, -0.6823],\n",
              "         [-1.2705, -3.0797, -0.7016, -3.0688,  0.7253,  0.7293,  6.1000],\n",
              "         [ 7.6070, -2.5106, -3.0227, -2.0992, -1.0515, -1.1190, -0.6119],\n",
              "         [-1.2399, -2.2512, -2.5366, -0.3096, -2.3144,  5.7405, -0.6278],\n",
              "         [ 0.0374, -2.7026, -1.2432, -3.1503,  0.2566, -0.7135,  6.1357],\n",
              "         [ 7.0126, -2.2660, -3.1678, -2.0898, -0.9910, -0.8260, -0.5479],\n",
              "         [ 6.3433, -2.6451, -3.1989, -1.9304, -1.3802, -0.9575, -0.1367],\n",
              "         [ 5.9450, -2.6924, -2.9546, -2.3872, -0.9686, -1.1456,  0.6077],\n",
              "         [ 7.0521, -2.3640, -3.1610, -1.4510, -1.6529, -0.7498, -0.9963],\n",
              "         [ 1.9753, -1.7750, -1.9326, -0.9397, -0.8321,  0.4471,  0.1944]]]), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm6pNVCOXBP5",
        "outputId": "be804434-64d2-4483-b6ff-d42ca5690ce3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "pIV9SUAp3RWc"
      },
      "outputs": [],
      "source": [
        "# 推理模型\n",
        "sentence = '日本外务省3月18日发布消息称，日本首相岸田文雄将于19至21日访问印度和柬埔寨。'\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "# 部署模型\n",
        "# 你可以使用保存的模型加载并在其他地方使用，例如在Flask或FastAPI中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8PQOG_D3iK7",
        "outputId": "b5d39fb6-809f-49d6-fae8-71f85c431586"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 1, 2,\n",
              "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 6, 0, 0])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7K2dQ13J2Nz",
        "outputId": "adee3962-30eb-477c-8df2-23c370172896"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40,\n",
              " 41,\n",
              " ['日',\n",
              "  '本',\n",
              "  '外',\n",
              "  '务',\n",
              "  '省',\n",
              "  '3',\n",
              "  '月',\n",
              "  '1',\n",
              "  '8',\n",
              "  '日',\n",
              "  '发',\n",
              "  '布',\n",
              "  '消',\n",
              "  '息',\n",
              "  '称',\n",
              "  '，',\n",
              "  '日',\n",
              "  '本',\n",
              "  '首',\n",
              "  '相',\n",
              "  '岸',\n",
              "  '田',\n",
              "  '文',\n",
              "  '雄',\n",
              "  '将',\n",
              "  '于',\n",
              "  '1',\n",
              "  '9',\n",
              "  '至',\n",
              "  '2',\n",
              "  '1',\n",
              "  '日',\n",
              "  '访',\n",
              "  '问',\n",
              "  '印',\n",
              "  '度',\n",
              "  '和',\n",
              "  '柬',\n",
              "  '埔',\n",
              "  '寨',\n",
              "  '。'])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(predictions), len(list(sentence)), list(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVRR2pF45slO",
        "outputId": "fe77aa3e-ea51-407d-e08c-a347eef343a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('日', 3)\n",
            "('本', 4)\n",
            "('外', 4)\n",
            "('务', 4)\n",
            "('省', 4)\n",
            "('3', 0)\n",
            "('月', 0)\n",
            "('1', 0)\n",
            "('8', 0)\n",
            "('日', 0)\n",
            "('发', 0)\n",
            "('布', 0)\n",
            "('消', 0)\n",
            "('息', 0)\n",
            "('称', 0)\n",
            "('，', 5)\n",
            "('日', 6)\n",
            "('本', 0)\n",
            "('首', 0)\n",
            "('相', 1)\n",
            "('岸', 2)\n",
            "('田', 2)\n",
            "('文', 2)\n",
            "('雄', 0)\n",
            "('将', 0)\n",
            "('于', 0)\n",
            "('1', 0)\n",
            "('9', 0)\n",
            "('至', 0)\n",
            "('2', 0)\n",
            "('1', 0)\n",
            "('日', 5)\n",
            "('访', 6)\n",
            "('问', 0)\n",
            "('印', 5)\n",
            "('度', 6)\n",
            "('和', 6)\n",
            "('柬', 0)\n"
          ]
        }
      ],
      "source": [
        "for i in zip(list(sentence), predictions[1:-1]):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "VXPeYcMF6mDI"
      },
      "outputs": [],
      "source": [
        "# 推理模型\n",
        "sentence1 = '岸田文雄将于19日访问印度和柬埔寨。..'\n",
        "inputs = tokenizer(sentence1, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs1 = model(**inputs)\n",
        "    predictions1 = torch.argmax(outputs1.logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "# 部署模型\n",
        "# 你可以使用保存的模型加载并在其他地方使用，例如在Flask或FastAPI中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_7ogpRM64kS",
        "outputId": "d4afcfda-3ba8-4c00-c817-88d9f688887a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('岸', 1)\n",
            "('田', 2)\n",
            "('文', 2)\n",
            "('雄', 2)\n",
            "('将', 0)\n",
            "('于', 0)\n",
            "('1', 0)\n",
            "('日', 0)\n",
            "('访', 0)\n",
            "('问', 0)\n",
            "('印', 5)\n",
            "('度', 6)\n",
            "('和', 0)\n",
            "('柬', 5)\n",
            "('埔', 6)\n",
            "('寨', 6)\n",
            "('。', 0)\n",
            "('.', 0)\n",
            "('.', 0)\n"
          ]
        }
      ],
      "source": [
        "for i in zip(list(sentence1), predictions1[1:-1]):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIYws9khMYPX",
        "outputId": "c8ce14eb-810e-4f43-cbed-ae5a61201567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('岸', 1)\n",
            "('田', 2)\n",
            "('文', 2)\n",
            "('雄', 2)\n",
            "('将', 0)\n",
            "('于', 0)\n",
            "('1', 0)\n",
            "('9', 0)\n",
            "('日', 0)\n",
            "('访', 0)\n",
            "('问', 5)\n",
            "('印', 6)\n",
            "('度', 0)\n",
            "('和', 5)\n",
            "('柬', 6)\n",
            "('埔', 6)\n",
            "('寨', 0)\n",
            "('。', 0)\n",
            "('.', 0)\n"
          ]
        }
      ],
      "source": [
        "for i in zip(list(sentence1), predictions1[1:-1]):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHEn4KDVMuhC",
        "outputId": "0735522c-d7e6-4d4a-848a-57b07387ad26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(str, '[CLS] 岸 田 文 雄 将 于 19 日 访 问 印 度 和 柬 埔 寨 。.. [SEP]')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(tokenizer.decode(out['input_ids'][0]))\n",
        "orgin_token = tokenizer.decode(inputs['input_ids'][0])\n",
        "type(orgin_token), orgin_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87umbFRvNQhl",
        "outputId": "7375fe69-a5bf-496c-a0d1-47a70574e1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('[CLS]', 0)\n",
            "('岸', 1)\n",
            "('田', 2)\n",
            "('文', 2)\n",
            "('雄', 2)\n",
            "('将', 0)\n",
            "('于', 0)\n",
            "('19', 0)\n",
            "('日', 0)\n",
            "('访', 0)\n",
            "('问', 0)\n",
            "('印', 5)\n",
            "('度', 6)\n",
            "('和', 0)\n",
            "('柬', 5)\n",
            "('埔', 6)\n",
            "('寨', 6)\n",
            "('。..', 0)\n",
            "('[SEP]', 0)\n"
          ]
        }
      ],
      "source": [
        "for j in zip(orgin_token.split(' '), predictions1):\n",
        "    print(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvjPRQNY7n9f",
        "outputId": "0374ecb8-c6ad-45ce-9f83-3083171dde96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HpIZ7UxYgvS"
      },
      "source": [
        "### 模型推理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2xcZazuOBBS",
        "outputId": "c8881e90-352d-4a4a-c047-ca1b0522c31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4kHmfnRLlTI"
      },
      "source": [
        "### gpt代码\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3JMH_doKXK3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 加载数据集\n",
        "dataset = load_dataset(\"peoples_daily_ner\")\n",
        "\n",
        "# 初始化BERT tokenizer和模型\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-chinese\", num_labels=len(dataset[\"train\"].features[\"ner_tags\"].feature))\n",
        "\n",
        "# 将数据集转换为适用于BERT的格式\n",
        "def tokenize_and_align_labels(example):\n",
        "    tokens = tokenizer.tokenize(example[\"tokens\"])\n",
        "    labels = example[\"ner_tags\"]\n",
        "    return {\"input_ids\": tokenizer.convert_tokens_to_ids(tokens),\n",
        "            \"attention_mask\": [1] * len(tokens),\n",
        "            \"labels\": labels}\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# 准备数据加载器\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True)\n",
        "eval_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=8)\n",
        "\n",
        "# 移动模型到GPU上\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 定义优化器和损失函数\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 训练模型\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "for epoch in range(3):\n",
        "    # 训练\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Train\"):\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        outputs = model(**inputs)\n",
        "        loss = loss_fn(outputs.logits.view(-1, len(dataset[\"train\"].features[\"ner_tags\"].feature)), labels.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        epoch_train_loss += loss.item()\n",
        "    train_losses.append(epoch_train_loss / len(train_dataloader))\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    epoch_eval_loss = 0\n",
        "    for batch in tqdm(eval_dataloader, desc=f\"Epoch {epoch+1} Eval\"):\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs.logits.view(-1, len(dataset[\"train\"].features[\"ner_tags\"].feature)), labels.view(-1))\n",
        "            epoch_eval_loss += loss.item()\n",
        "    eval_losses.append(epoch_eval_loss / len(eval_dataloader))\n",
        "\n",
        "# 绘制训练损失曲线\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(eval_losses, label='Eval')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Evaluation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 保存模型\n",
        "model.save_pretrained(\"./peoples_daily_ner_model\")\n",
        "\n",
        "# 推理模型\n",
        "example_sentence = \"北京是中国的首都。\"\n",
        "inputs = tokenizer(example_sentence, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "# 部署模型\n",
        "# 你可以使用保存的模型加载并在其他地方使用，例如在Flask或FastAPI中。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMUDtHHz17M80SdsS+mOGtV",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0801be1ae369464c9c4bb5707f077b09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16e96c3bb76b46be87a625998ff9076c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ab0df3ba53e4791990f95c1a2936130",
              "IPY_MODEL_a718d0a1bb6b41be93dcc817472d3f43",
              "IPY_MODEL_caf7af5a108b45298c0064c34450c7b2"
            ],
            "layout": "IPY_MODEL_36ab9baa2d344ae68ff64a73662f77fb"
          }
        },
        "17df221428e341359cc18f3a6fc53185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "282e386056354a949485ee336c80f085": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36ab9baa2d344ae68ff64a73662f77fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab0df3ba53e4791990f95c1a2936130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0801be1ae369464c9c4bb5707f077b09",
            "placeholder": "​",
            "style": "IPY_MODEL_282e386056354a949485ee336c80f085",
            "value": "model.safetensors: 100%"
          }
        },
        "80997242f67a4885a190611556d33053": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93810da730a74212b5478c2b143adbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a718d0a1bb6b41be93dcc817472d3f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa0bce7220f64fe9b4c76ec10779f211",
            "max": 411553788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17df221428e341359cc18f3a6fc53185",
            "value": 411553788
          }
        },
        "caf7af5a108b45298c0064c34450c7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80997242f67a4885a190611556d33053",
            "placeholder": "​",
            "style": "IPY_MODEL_93810da730a74212b5478c2b143adbd7",
            "value": " 412M/412M [00:03&lt;00:00, 134MB/s]"
          }
        },
        "fa0bce7220f64fe9b4c76ec10779f211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
